{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17f6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4db93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/17 16:08:34 WARN Utils: Your hostname, bruno-cpu resolves to a loopback address: 127.0.1.1; using 10.0.0.227 instead (on interface wlp2s0)\n",
      "22/11/17 16:08:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/17 16:08:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"4g\").appName('chapter_2').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd58531",
   "metadata": {},
   "source": [
    "### Setting Up Our Data\n",
    "\n",
    "From the shell:\n",
    "\n",
    "```\n",
    "$ mkdir linkage\n",
    "$ cd linkage/\n",
    "$ curl -L -o donation.zip https://bit.ly/1Aoywaq\n",
    "$ unzip donation.zip\n",
    "$ unzip 'block_*.zip'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e107825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev = spark.read.csv(\"data/linkage/block_*.csv\")\n",
    "\n",
    "prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4accf16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| _c0| _c1|         _c2|         _c3|         _c4|         _c5|    _c6|   _c7|   _c8|   _c9|   _c10|    _c11|\n",
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|id_1|id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "|3148|8326|           1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prev.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5ddd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "parsed = spark.read.option(\"header\", \"true\").option(\"nullValue\", \"?\").\\\n",
    "          option(\"inferSchema\", \"true\").csv(\"data/linkage/block*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4457ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_fname_c2: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c2: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c79be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Row(id_1=3148, id_2=8326, cmp_fname_c1=1.0, cmp_fname_c2=None, cmp_lname_c1=1.0, cmp_lname_c2=None, cmp_sex=1, cmp_bd=1, cmp_bm=1, cmp_by=1, cmp_plz=1, is_match=True)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d05731",
   "metadata": {},
   "source": [
    "### Analyzing Data with the DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96e9eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_fname_c2: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c2: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| 3148| 8326|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|14055|94934|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|33948|34740|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|  946|71870|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|64880|71676|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.printSchema()\n",
    "\n",
    "parsed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b63bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "5749132"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d456d900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[id_1: int, id_2: int, cmp_fname_c1: double, cmp_fname_c2: double, cmp_lname_c1: double, cmp_lname_c2: double, cmp_sex: int, cmp_bd: int, cmp_bm: int, cmp_by: int, cmp_plz: int, is_match: boolean]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "847c09b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|is_match|  count|\n",
      "+--------+-------+\n",
      "|   false|5728201|\n",
      "|    true|  20931|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "parsed.groupBy(\"is_match\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dbc69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed.createOrReplaceTempView(\"linkage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a197fa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|is_match|    cnt|\n",
      "+--------+-------+\n",
      "|   false|5728201|\n",
      "|    true|  20931|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT is_match, COUNT(*) cnt\n",
    "  FROM linkage\n",
    "  GROUP BY is_match\n",
    "  ORDER BY cnt DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1493d3",
   "metadata": {},
   "source": [
    "### Fast Summary Statistics for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = parsed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a15147",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = parsed.where(\"is_match = true\")\n",
    "match_summary = matches.describe()\n",
    "\n",
    "misses = parsed.filter(col(\"is_match\") == False)\n",
    "miss_summary = misses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483c8ade",
   "metadata": {},
   "source": [
    "### PIvoting and Reshaping DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805cc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_p = summary.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59057e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_p.head()\n",
    "...\n",
    "summary_p.shape\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694a70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_p = summary_p.set_index('summary').transpose().reset_index()\n",
    "...\n",
    "summary_p = summary_p.rename(columns={'index':'field'})\n",
    "...\n",
    "summary_p = summary_p.rename_axis(None, axis=1)\n",
    "...\n",
    "summary_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03227118",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryT = spark.createDataFrame(summary_p)\n",
    "...\n",
    "summaryT.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ad128",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryT.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "for c in summaryT.columns:\n",
    "    if c == 'field':\n",
    "        continue\n",
    "    summaryT = summaryT.withColumn(c, summaryT[c].cast(DoubleType()))\n",
    "...\n",
    "summaryT.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db58aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def pivot_summary(desc):\n",
    "    # convert to pandas dataframe\n",
    "    desc_p = desc.toPandas()\n",
    "    # transpose\n",
    "    desc_p = desc_p.set_index('summary').transpose().reset_index()\n",
    "    desc_p = desc_p.rename(columns={'index':'field'})\n",
    "    desc_p = desc_p.rename_axis(None, axis=1)\n",
    "    # convert to Spark dataframe\n",
    "    descT = spark.createDataFrame(desc_p)\n",
    "    # convert metric columns to double from string\n",
    "    for c in descT.columns:\n",
    "        if c == 'field':\n",
    "            continue\n",
    "        else:\n",
    "            descT = descT.withColumn(c, descT[c].cast(DoubleType()))\n",
    "        return descT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80124e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_summaryT = pivot_summary(match_summary)\n",
    "miss_summaryT = pivot_summary(miss_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17e98f",
   "metadata": {},
   "source": [
    "### Joining DataFrames and Selecting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_summaryT.createOrReplaceTempView(\"match_desc\")\n",
    "miss_summaryT.createOrReplaceTempView(\"miss_desc\")\n",
    "spark.sql(\"\"\"\n",
    "  SELECT a.field, a.count + b.count total, a.mean - b.mean delta\n",
    "  FROM match_desc a INNER JOIN miss_desc b ON a.field = b.field\n",
    "  WHERE a.field NOT IN (\"id_1\", \"id_2\")\n",
    "  ORDER BY delta DESC, total DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c8748",
   "metadata": {},
   "source": [
    "### Scoring and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_features = [\"cmp_lname_c1\", \"cmp_plz\", \"cmp_by\", \"cmp_bd\", \"cmp_bm\"]\n",
    "...\n",
    "sum_expression = \" + \".join(good_features)\n",
    "...\n",
    "sum_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9239692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "scored = parsed.fillna(0, subset=good_features).\\\n",
    "                withColumn('score', expr(sum_expression)).\\\n",
    "                select('score', 'is_match')\n",
    "...\n",
    "scored.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossTabs(scored: DataFrame, t: DoubleType) -> DataFrame:\n",
    "    return  scored.selectExpr(f\"score >= {t} as above\", \"is_match\").\\\n",
    "          groupBy(\"above\").pivot(\"is_match\", (\"true\", \"false\")).\\\n",
    "          count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ede503",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossTabs(scored, 4.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0de336",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossTabs(scored, 2.0).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}